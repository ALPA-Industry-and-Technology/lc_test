{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Ignore all warnings (not recommended in production code)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your API keys from environment variables\n",
    "load_dotenv()\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "huggingface_token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load VectorDB from disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from disk\n",
    "embedding = OpenAIEmbeddings()\n",
    "persist_directory = 'db'\n",
    "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Documents similar to Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Dear Fellow Scholars, this is Two Minute Papers with Dr. KÃ¡roly Zsolnai-FehÃ©r. Today, we are going to have a look at an image creation AI called Perfusion that is completely out of this world. Imagine a text-to-image AI like Stable Diffusion or Meat Journey as a chef that can cook any dish. However, sometimes, we like the dish we get, but we would like to introduce our own ingredients to it. And normally, if we write a new recipe, a new text prompt, we get a completely new image, a new dish. However, that is not what we want. What we want is the previous dish with a new ingredient. Let's have a look at an example. We have photos of our favorite teddy bear, and we would like it to create an image of it playing with a ball in the water. A previous technique doesâ€¦uh-oh. I have already looked at this image, and I have bad news. It's not going to be pretty. Are you ready? Okay, here you go! Whoa! It seems to have fallen apart, and there is no ball anywhere to be seen. Now, let's look at\", metadata={'source': 'documents\\\\NVIDIAs_New_AI_Text_To_Image_Supercharged.txt'}),\n",
       " Document(page_content=\"Dear Fellow Scholars, this is Two Minute Papers with Dr. KÃ¡roly Zsolnai-FehÃ©r. Today, we are going to have a look at an image creation AI called Perfusion that is completely out of this world. Imagine a text-to-image AI like Stable Diffusion or Meat Journey as a chef that can cook any dish. However, sometimes, we like the dish we get, but we would like to introduce our own ingredients to it. And normally, if we write a new recipe, a new text prompt, we get a completely new image, a new dish. However, that is not what we want. What we want is the previous dish with a new ingredient. Let's have a look at an example. We have photos of our favorite teddy bear, and we would like it to create an image of it playing with a ball in the water. A previous technique doesâ€¦uh-oh. I have already looked at this image, and I have bad news. It's not going to be pretty. Are you ready? Okay, here you go! Whoa! It seems to have fallen apart, and there is no ball anywhere to be seen. Now, let's look at\", metadata={'source': 'documents\\\\NVIDIAs_New_AI_Text_To_Image_Supercharged.txt'}),\n",
       " Document(page_content='Policy Discussion Paper \\nThe Use of Artificial Intelligence  \\nand Machine Learning in the  Financial Sector © nobeastsofierce - stock.adobe.com\\nDirectorate General Banking and Financial Supervision  November 2020', metadata={'page': 0, 'source': 'documents\\\\2020-11-policy-dp-aiml-data.pdf'})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = vectordb.similarity_search(\"Dear Fellow Scholars, this is Two Minute Papers with Dr\", k = 3)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Simple RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Dear Fellow Scholars, this is Two Minute Papers with Dr. KÃ¡roly Zsolnai-FehÃ©r. Today, we are going to have a look at an image creation AI called Perfusion that is completely out of this world. Imagine a text-to-image AI like Stable Diffusion or Meat Journey as a chef that can cook any dish. However, sometimes, we like the dish we get, but we would like to introduce our own ingredients to it. And normally, if we write a new recipe, a new text prompt, we get a completely new image, a new dish. However, that is not what we want. What we want is the previous dish with a new ingredient. Let's have a look at an example. We have photos of our favorite teddy bear, and we would like it to create an image of it playing with a ball in the water. A previous technique doesâ€¦uh-oh. I have already looked at this image, and I have bad news. It's not going to be pretty. Are you ready? Okay, here you go! Whoa! It seems to have fallen apart, and there is no ball anywhere to be seen. Now, let's look at\", metadata={'source': 'documents\\\\NVIDIAs_New_AI_Text_To_Image_Supercharged.txt'})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I consider only top k=1 candidate as chunksize is large\n",
    "# In real app we would reduce chunk size to smaller chunks \n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 1}) \n",
    "docs = retriever.get_relevant_documents(\"Someone said this is X Minute Papers. How many minutes were they?\")\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function to add some meta data for fact checking\n",
    "def process_llm_response(llm_response):\n",
    "    print(f\"AI Response:\\n{llm_response['result']}\")\n",
    "    print('\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=OpenAI(), \n",
    "                                  chain_type=\"stuff\", \n",
    "                                  retriever=retriever, \n",
    "                                  return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Response:\n",
      " This is Two Minute Papers with Dr. Károly Zsolnai-Fehér.\n",
      "\n",
      "Sources:\n",
      "documents\\NVIDIAs_New_AI_Text_To_Image_Supercharged.txt\n"
     ]
    }
   ],
   "source": [
    "query = \"Someone said this is X Minute Papers. How many minutes were they and what is the name of the Dr?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".langchain_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
