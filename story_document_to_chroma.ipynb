{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Ignore all warnings (not recommended in production code)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "huggingface_token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_loader = DirectoryLoader('./documents/', glob=\"./*.pdf\", loader_cls=PyPDFLoader)\n",
    "pdf_documents = pdf_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if verbose:\n",
    "    for document in pdf_documents:\n",
    "        print(document.metadata[\"source\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "pdf_chunks = text_splitter.split_documents(pdf_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup ChromaDB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## here we are using OpenAI embeddings but in future we will swap out to something else\n",
    "embedding = OpenAIEmbeddings()\n",
    "persist_directory = 'db'\n",
    "\n",
    "# Batch chunk embedding + insert to DB\n",
    "vectordb = Chroma.from_documents(documents=pdf_chunks, \n",
    "                                 embedding=embedding,\n",
    "                                 persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load VectorDB from disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from disk\n",
    "vectordb = None # Pretent we want to load db\n",
    "\n",
    "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert new Document Chunks to DB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_loader = DirectoryLoader('./documents/', glob=\"./*.txt\", loader_cls=TextLoader) # ***\n",
    "txt_documents = txt_loader.load()\n",
    "\n",
    "# *** Hint: The shitty thing with the DirectoryLoader is that you cannot enforce utf-8 encoding\n",
    "# *         this needs to be done with  TextLoader that works on file-level\n",
    "# *         workaround for future: OwnDirectoryLoader \n",
    "\n",
    "txt_chunks = text_splitter.split_documents(txt_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['109d4819-5280-11ee-ac93-b06088bbcb77',\n",
       " '109d481a-5280-11ee-b7ad-b06088bbcb77',\n",
       " '109d481b-5280-11ee-82b9-b06088bbcb77',\n",
       " '109d481c-5280-11ee-bdf1-b06088bbcb77',\n",
       " '109d481d-5280-11ee-b46c-b06088bbcb77']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vectordb.add_documents(txt_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Documents similar to Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Dear Fellow Scholars, this is Two Minute Papers with Dr. KÃ¡roly Zsolnai-FehÃ©r. Today, we are going to have a look at an image creation AI called Perfusion that is completely out of this world. Imagine a text-to-image AI like Stable Diffusion or Meat Journey as a chef that can cook any dish. However, sometimes, we like the dish we get, but we would like to introduce our own ingredients to it. And normally, if we write a new recipe, a new text prompt, we get a completely new image, a new dish. However, that is not what we want. What we want is the previous dish with a new ingredient. Let's have a look at an example. We have photos of our favorite teddy bear, and we would like it to create an image of it playing with a ball in the water. A previous technique doesâ€¦uh-oh. I have already looked at this image, and I have bad news. It's not going to be pretty. Are you ready? Okay, here you go! Whoa! It seems to have fallen apart, and there is no ball anywhere to be seen. Now, let's look at\", metadata={'source': 'documents\\\\NVIDIAs_New_AI_Text_To_Image_Supercharged.txt'}),\n",
       " Document(page_content=\"Dear Fellow Scholars, this is Two Minute Papers with Dr. KÃ¡roly Zsolnai-FehÃ©r. Today, we are going to have a look at an image creation AI called Perfusion that is completely out of this world. Imagine a text-to-image AI like Stable Diffusion or Meat Journey as a chef that can cook any dish. However, sometimes, we like the dish we get, but we would like to introduce our own ingredients to it. And normally, if we write a new recipe, a new text prompt, we get a completely new image, a new dish. However, that is not what we want. What we want is the previous dish with a new ingredient. Let's have a look at an example. We have photos of our favorite teddy bear, and we would like it to create an image of it playing with a ball in the water. A previous technique doesâ€¦uh-oh. I have already looked at this image, and I have bad news. It's not going to be pretty. Are you ready? Okay, here you go! Whoa! It seems to have fallen apart, and there is no ball anywhere to be seen. Now, let's look at\", metadata={'source': 'documents\\\\NVIDIAs_New_AI_Text_To_Image_Supercharged.txt'}),\n",
       " Document(page_content='Policy Discussion Paper \\nThe Use of Artificial Intelligence  \\nand Machine Learning in the  Financial Sector © nobeastsofierce - stock.adobe.com\\nDirectorate General Banking and Financial Supervision  November 2020', metadata={'page': 0, 'source': 'documents\\\\2020-11-policy-dp-aiml-data.pdf'})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = vectordb.similarity_search(\"Dear Fellow Scholars, this is Two Minute Papers with Dr\", k = 3)\n",
    "docs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".langchain_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
